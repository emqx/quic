Write down some notes for internal implementations.

* Handle Lifecycle
** What is Handle

In erlang code, Handle (a handle term) is a REF to the contexts and they are

- Listener handle

  For accessing l_ctx (Listener Context)

- Connection handle

  For accessing c_ctx (Connection Context)

- Stream handle

  For accessing s_ctx (Stream Context)

`*_ctx` is the NIF resource object in C code, and it has

1. A MsQuic handle (HQUIC) for interworking with MsQuic.
2. A 'is_closed' boolean flag mark if the HQUIC is valid or not.
   If it is false, the HQUIC may become (or is becoming) invalid and it is unsafe to be used for calling MsQuic APIs.
3. ... Other members(fields) are irrelevant here.

** Creation

Creation is the op of allocating NIF resources.

*** Listener handle

Created in quicer_nif:listen/2

*** Connection handle

In init_c_ctx

1. server: ctx is created in listener callback when there is new incoming connection
2. client: ctx is created in quicer_nif:async_connect3/3

*** Stream handle

In init_s_ctx

1. server: ctx is created in conn callback
2. client: ctx is created in quicer_nif:async_start_stream2/2

** Destroy

In erlang vm, if there is a var holding the handle, it will not be garbage collected.

Same as in C NIF code, if the handle is one of the input arguments, it is safe to access the *_ctx because the var in erlang is still holding the handle but we cannot assume the API caller will hold the handle for the entire lifecycle.

** Thread Safety with ref counting.

In C code, the resource object is not deallocated (become *invalid**) until the last handle term is garbage collected by the VM and the resource is released with enif_release_resource (not necessarily in that order).
note, The refcounting is very expensive call.

Access a *invalid* resource object via the pointer could cause SEGFAULT.

In term of thread safety, There are three players in quicer that could access the resource object simultaneously.

a. The MsQuic worker thread is accessing *_ctx in the callback function
b. VM scheduler is executing a NIF function such as quicer:send/2
c. VM scheduler thread is doing GC of the handle object

After the context object is created, the refcnt is 1

1. VM ensures the c) happens last when refcnt is 0.

2. In the nif function that needs to access the resource object:

   +call enif_keep_resource before the access+

   +call enif_release_resource after the access+

   At the time of accessing resource object, the Var is still refereced and it will not be garbage collected.

   It is unnecessary to keep/release the resources.

   Note @TODO, unsure this is still true for the NIF that runs on dirty scheduler.

3. In the nif function that calls the MsQuic API which can cause later accessing resource object in the callback context in the msquic worker thread.

   It is unnecessary to keep/release the resources.

4. In MsQuic callback function when handling the event of 'SHUTDOWN COMPLETE'

   'SHUTDOWN COMPLETE' means resource is no longer active and there will be no more callbacks
   (Connection->ClientCallbackHandle = NULL)

   Callback should decrease the refcnt.

   In callback,
     Call enif_release_resource
     Set msquic Handle to NULL within locking context.
     Msquic API could deal with NULL handle.

5. In MsQuic callback function and NIF function

   When the high-level resource object is created on top of a lower level.

   For example: when a stream is created in a connection, we need to call enif_keep_resource for connection resource object bump the refcnt.

6. Deinit the resource object in resource destruct function ~resource_*_dealloc_callback~

   Call enif_release_resource for corresponding lower-level resource object.

   For instance, when deinit the s_ctx, it should deref the c_ctx.

   Everything contained in the resource object becomes invalid and it will be impossible to access the destructed
   resource obj from a) and b). But for accessing from c) it is out of our control.

   Close the msquic handle.

7. When close the connection via quicer_nif:close_connection3

   Set Connection Handle to NULL within locked context

8. MsQuic callback signaling

   NO-OP

9. @TODO: Catch runtime error signals from msquic
    To not 'crash' the erlang VM. we need some signal handling to handle the runtime error signals from msquic such as runtime assertions and raise an alarm for 'need maintaince'.

    If the resource that links to the error is identical, we could try to mark it blacklisted and deny further access.

*** Connection Client

The connection ctx resource is *created* in NIF quicer:async_connect.

enif_release_resource is called in 'destroy_c_ctx'.

*** Connection Server

The connection ctx resource is *created* in 'ServerListenerCallback'.

enif_release_resource is called in 'destroy_c_ctx'.

*** Stream Client

For the stream init from client
The stream ctx resource is *created* in 'async_start_stream2'.
Client call enif_keep_resource on the connection ctx which it belongs to.

For the stream init from server
The stream ctx resource is *created* in 'ClientConnectionCallback'.
Client call enif_keep_resource on the connection ctx which it belongs to.

enif_release_resource is called in 'destroy_s_ctx'.
enif_release_resource of connection ctx is called in 'destroy_c_ctx'.

*** Stream Server
The stream ctx resource is *created* in 'ServerConnectionCallback'.
Then call enif_keep_resource on the connection ctx which it belongs to.

enif_release_resource is called in 'destroy_s_ctx'.
enif_release_resource of connection ctx is called in 'destroy_c_ctx'.


* MsQuic API Usages

List how we map the API of MsQuic

** API Table
#+begin_src c
typedef struct QUIC_API_TABLE {

    QUIC_SET_CONTEXT_FN                 SetContext;
    QUIC_GET_CONTEXT_FN                 GetContext;
    QUIC_SET_CALLBACK_HANDLE_FN        SetCallbackHandle;

    QUIC_SET_PARAM_FN                   SetParam;
    QUIC_GET_PARAM_FN                   GetParam;

    QUIC_REGISTRATION_OPEN_FN           RegistrationOpen;
    QUIC_REGISTRATION_CLOSE_FN          RegistrationClose;
    QUIC_REGISTRATION_SHUTDOWN_FN       RegistrationShutdown;

    QUIC_CONFIGURATION_OPEN_FN          ConfigurationOpen;
    QUIC_CONFIGURATION_CLOSE_FN         ConfigurationClose;
    QUIC_CONFIGURATION_LOAD_CREDENTIAL_FN
                                        ConfigurationLoadCredential;

    QUIC_LISTENER_OPEN_FN               ListenerOpen;
    QUIC_LISTENER_CLOSE_FN              ListenerClose;
    QUIC_LISTENER_START_FN              ListenerStart;
    QUIC_LISTENER_STOP_FN               ListenerStop;

    QUIC_CONNECTION_OPEN_FN             ConnectionOpen;
    QUIC_CONNECTION_CLOSE_FN            ConnectionClose;
    QUIC_CONNECTION_SHUTDOWN_FN         ConnectionShutdown;
    QUIC_CONNECTION_START_FN            ConnectionStart;
    QUIC_CONNECTION_SET_CONFIGURATION_FN
                                        ConnectionSetConfiguration;
    QUIC_CONNECTION_SEND_RESUMPTION_FN  ConnectionSendResumptionTicket;

    QUIC_STREAM_OPEN_FN                 StreamOpen;
    QUIC_STREAM_CLOSE_FN                StreamClose;
    QUIC_STREAM_START_FN                StreamStart;
    QUIC_STREAM_SHUTDOWN_FN             StreamShutdown;
    QUIC_STREAM_SEND_FN                 StreamSend;
    QUIC_STREAM_RECEIVE_COMPLETE_FN     StreamReceiveComplete;
    QUIC_STREAM_RECEIVE_SET_ENABLED_FN  StreamReceiveSetEnabled;

    QUIC_DATAGRAM_SEND_FN               DatagramSend;

}
#+end_src

** APIs

*** SetContext [Not Used]
*** GetContext [Not Used]
*** SetCallbackHandle
*** SetParam
SYNC call in non-callback-context
*** GetParam
SYNC call in non-callback-context
*** RegistrationOpen;
*** RegistrationClose;
*** RegistrationShutdown; [Not Used]
*** ConfigurationOpen;
*** ConfigurationClose;
*** ConfigurationLoadCredential;
*** ListenerOpen;
*** ListenerClose;
*** ListenerStart;
*** ListenerStop;
*** ConnectionOpen;
*** ConnectionClose;
SYNC call in non-callback-context
*** ConnectionShutdown;
*** ConnectionStart;
*** ConnectionSetConfiguration;
*** ConnectionSendResumptionTicket;

*** StreamOpen;
*** StreamClose;
SYNC call in non-callback-context
*** StreamStart;
*** StreamShutdown;
*** StreamSend;
*** StreamReceiveComplete;
*** StreamReceiveSetEnabled;
*** DatagramSend;


*** API Types (number in tracing)
#+begin_verse
QUIC_TRACE_API_SET_PARAM,   // 0
QUIC_TRACE_API_GET_PARAM,   // 1
QUIC_TRACE_API_REGISTRATION_OPEN , // 2
QUIC_TRACE_API_REGISTRATION_CLOSE, // 3
QUIC_TRACE_API_REGISTRATION_SHUTDOWN, // 4
QUIC_TRACE_API_CONFIGURATION_OPEN, // 5
QUIC_TRACE_API_CONFIGURATION_CLOSE, // 6
QUIC_TRACE_API_CONFIGURATION_LOAD_CREDENTIAL, // 7
QUIC_TRACE_API_LISTENER_OPEN, // 8
QUIC_TRACE_API_LISTENER_CLOSE, // 9
QUIC_TRACE_API_LISTENER_START, // 10
QUIC_TRACE_API_LISTENER_STOP, // 11
QUIC_TRACE_API_CONNECTION_OPEN, // 12
QUIC_TRACE_API_CONNECTION_CLOSE, // 13
QUIC_TRACE_API_CONNECTION_SHUTDOWN, // 14
QUIC_TRACE_API_CONNECTION_START, // 15
QUIC_TRACE_API_CONNECTION_SET_CONFIGURATION, // 16
QUIC_TRACE_API_CONNECTION_SEND_RESUMPTION_TICKET, // 17
QUIC_TRACE_API_STREAM_OPEN, // 18
QUIC_TRACE_API_STREAM_CLOSE, // 19
QUIC_TRACE_API_STREAM_START, // 20
QUIC_TRACE_API_STREAM_SHUTDOWN, // 21
QUIC_TRACE_API_STREAM_SEND, // 22
QUIC_TRACE_API_STREAM_RECEIVE_COMPLETE, // 23
QUIC_TRACE_API_STREAM_RECEIVE_SET_ENABLED, // 24
QUIC_TRACE_API_DATAGRAM_SEND, // 25
QUIC_TRACE_API_COUNT // 26
#+end_verse

* Event handling
** Listener Events

*QUIC_LISTENER_EVENT* in msquic.h

#+begin_verse
    QUIC_LISTENER_EVENT_NEW_CONNECTION      = 0,
    QUIC_LISTENER_EVENT_STOP_COMPLETE       = 1,
#+end_verse

| MsQuic Event                       | Erlang Msg                                       |
|------------------------------------+--------------------------------------------------|
| QUIC_LISTENER_EVENT_NEW_CONNECTION | {quic,  new_conn         , connection_handle()}  |
| QUIC_LISTENER_EVENT_STOP_COMPLETE  | {quic,  listener_stopped , listener_handle()}    |

** Connecion Events

*QUIC_CONNECTION_EVENT* in msquic.h

#+begin_verse
    QUIC_CONNECTION_EVENT_CONNECTED                         = 0,
    QUIC_CONNECTION_EVENT_SHUTDOWN_INITIATED_BY_TRANSPORT   = 1,    // The transport started the shutdown process.
    QUIC_CONNECTION_EVENT_SHUTDOWN_INITIATED_BY_PEER        = 2,    // The peer application started the shutdown process.
    QUIC_CONNECTION_EVENT_SHUTDOWN_COMPLETE                 = 3,    // Ready for the handle to be closed.
    QUIC_CONNECTION_EVENT_LOCAL_ADDRESS_CHANGED             = 4,
    QUIC_CONNECTION_EVENT_PEER_ADDRESS_CHANGED              = 5,
    QUIC_CONNECTION_EVENT_PEER_STREAM_STARTED               = 6,
    QUIC_CONNECTION_EVENT_STREAMS_AVAILABLE                 = 7,
    QUIC_CONNECTION_EVENT_PEER_NEEDS_STREAMS                = 8,
    QUIC_CONNECTION_EVENT_IDEAL_PROCESSOR_CHANGED           = 9,
    QUIC_CONNECTION_EVENT_DATAGRAM_STATE_CHANGED            = 10,
    QUIC_CONNECTION_EVENT_DATAGRAM_RECEIVED                 = 11,
    QUIC_CONNECTION_EVENT_DATAGRAM_SEND_STATE_CHANGED       = 12,
    QUIC_CONNECTION_EVENT_RESUMED                           = 13,   // Server-only; provides resumption data, if any.
    QUIC_CONNECTION_EVENT_RESUMPTION_TICKET_RECEIVED        = 14,   // Client-only; provides ticket to persist, if any.
    QUIC_CONNECTION_EVENT_PEER_CERTIFICATE_RECEIVED         = 15,
#+end_verse


| MsQuic Event                                          | Erlang Msg                                                                 |
|-------------------------------------------------------+----------------------------------------------------------------------------|
| QUIC_CONNECTION_EVENT_CONNECTED                       | {quic, connected, connection_handle()}  @TODO more flags                  |
| QUIC_CONNECTION_EVENT_SHUTDOWN_INITIATED_BY_TRANSPORT | {quic, transport_shutdown, connection_handle(), atom_status()}            |
| QUIC_CONNECTION_EVENT_SHUTDOWN_INITIATED_BY_PEER      | {quic, shutdown, connection_handle(), ErrorCode::integer()}               |
| QUIC_CONNECTION_EVENT_SHUTDOWN_COMPLETE               | {quic, closed, connection_handle(), Flags::map()}                         |
| QUIC_CONNECTION_EVENT_LOCAL_ADDRESS_CHANGED           | {quic, local_address_changed, connection_handle(), addr_str()}            |
| QUIC_CONNECTION_EVENT_PEER_ADDRESS_CHANGED            | {quic, peer_address_changed, connection_handle(), addr_str()}             |
| QUIC_CONNECTION_EVENT_PEER_STREAM_STARTED             | {quic, new_stream, stream_handle(), new_stream_props()} stream            |
| QUIC_CONNECTION_EVENT_STREAMS_AVAILABLE               | {quic, streams_available, connection_handle(), BidirStmCnt, UniDirStmCnt} |
| QUIC_CONNECTION_EVENT_PEER_NEEDS_STREAMS              | {quic, peer_needs_streams, connection_handle()}                           |
| QUIC_CONNECTION_EVENT_IDEAL_PROCESSOR_CHANGED         | -                                                                          |
| QUIC_CONNECTION_EVENT_DATAGRAM_STATE_CHANGED          | {quic, dgram_max_len, integer()} @TODO with handle                        |
| QUIC_CONNECTION_EVENT_DATAGRAM_RECEIVED               | {quic, dgram, binary()}          @TODO with handle                        |
| QUIC_CONNECTION_EVENT_DATAGRAM_SEND_STATE_CHANGED     | {quic, send_dgram_completed, connection_handle()}                         |
| QUIC_CONNECTION_EVENT_RESUMED                         | {quic, connection_resumed, connection_handle, false \vert binary()}       |
| QUIC_CONNECTION_EVENT_RESUMPTION_TICKET_RECEIVED      | {quic, nst_received, connection_handle(), Ticket::binary()}               |
| QUIC_CONNECTION_EVENT_PEER_CERTIFICATE_RECEIVED       | @TODO                                                                      |
|-------------------------------------------------------+----------------------------------------------------------------------------|


** Stream Events

*QUIC_STREAM_EVENT* in msquic.h

#+begin_verse
QUIC_STREAM_EVENT_START_COMPLETE            = 0,
QUIC_STREAM_EVENT_RECEIVE                   = 1,
QUIC_STREAM_EVENT_SEND_COMPLETE             = 2,
QUIC_STREAM_EVENT_PEER_SEND_SHUTDOWN        = 3,
QUIC_STREAM_EVENT_PEER_SEND_ABORTED         = 4,
QUIC_STREAM_EVENT_PEER_RECEIVE_ABORTED      = 5,
QUIC_STREAM_EVENT_SEND_SHUTDOWN_COMPLETE    = 6,
QUIC_STREAM_EVENT_SHUTDOWN_COMPLETE         = 7,
QUIC_STREAM_EVENT_IDEAL_SEND_BUFFER_SIZE    = 8,
QUIC_STREAM_EVENT_PEER_ACCEPTED             = 9,

#+end_verse
| MsQuic Event                             | Erlang Msg                                                                      |
|------------------------------------------+---------------------------------------------------------------------------------|
| QUIC_STREAM_EVENT_START_COMPLETE         | {quic, start_completed, #{}}                                                    |
| QUIC_STREAM_EVENT_RECEIVE                | {quic, stream_handle(), continue} or {quic, binary(), stream_handle(), map()} |
| QUIC_STREAM_EVENT_SEND_COMPLETE          | {quic, send_complete, stream_handle(), CanceledFlag}                           |
| QUIC_STREAM_EVENT_PEER_SEND_SHUTDOWN     | {quic, peer_send_shutdown, stream_handle(), undefined}                         |
| QUIC_STREAM_EVENT_PEER_SEND_ABORTED      | {quic, peer_send_aborted, stream_handle(), error_code()}                       |
| QUIC_STREAM_EVENT_PEER_RECEIVE_ABORTED   | {quic, peer_receive_aborted, stream_handle(), error_code()}                    |
| QUIC_STREAM_EVENT_SHUTDOWN_COMPLETE      | {quic, stream_closed, stream_handle(), #{}}                                    |
| QUIC_STREAM_EVENT_SEND_SHUTDOWN_COMPLETE | @TODO                                                                           |
| QUIC_STREAM_EVENT_IDEAL_SEND_BUFFER_SIZE | @TODO                                                                           |
| QUIC_STREAM_EVENT_PEER_ACCEPTED          | {quic, peer_accepted, stream_handle()}                                         |

* Multistreaming Support

Multistreaming is one of the core features QUIC brings to the transport layer.

Quicer support multistreaming in two levels

** NIF level

Caller of NIF functions in module quicer_nif is free to manage the streams after connection is established.

Both QUIC endpoints could
1. Start stream(s) with `quicer:start_stream`, other end accepts new streams
2. Send data over it with `quicer:send` or receive data passively or actively from process message box
3. Both side is able to shutdown/abort the stream with 'quicer:shutdown_stream' or 'quicer:close_stream'
   with flags.

** Erlang Process level

In quicer, for best practice, you could use quicer_* modules to manage the listeners, connections and streams.

- quicer_connection

  Process handles connections

- quicer_conn_acceptor_sup

  Supervisor that manages connection acceptors

- quicer_listener

  Supervised listener process

- quicer_listener_sup

  Supervisor that manages listener proceses

- quicer_server_conn_callback

  Example callback module for handle *server* connections.

* Active/Passive receive

** Function

Stream owner (the controlling process) gets the ordered stream binary actively or
passively depends on the stream recv modes:

- Active Mode:

  Binary is delivered to the stream owner process mailbox in the msg format of

  #+begin_src erlang
  {quic, binary(), stream_handle(), other_props()}.
  #+end_src

- Passive Mode:

  Call
  #+begin_src erlang
  quicer:recv(stream_handle(), number_of_bytes()).
  #+end_src

The recv mode could be set via stream opt `active` when starting the stream locally or accepting the remote stream
and get changed afterward via

#+begin_src erlang
quicer:setopts(stream(), active, Mode).
#+end_src

The active *Mode* is compatible with inet:setopts/2 as in https://www.erlang.org/doc/man/inet.html#setopts-2

** Implementations

*** Callback handle `QUIC_STREAM_EVENT_RECEIVE` with received binary in Active mode

The whole recv bytes will be delivered to the owner process. The integer `N` in {active, N} will be decreased by 1.
If it becomes 0, `{quic, passive, stream_handle(), undefined}` will be sent to the owner as well and stream recv mode
becomes passive.

If `N` is once, the stream recv mode will become passive mode and no `{quic, passive, stream_handle(), undefined}`
will be delivered to the owner.

When the stream enters passive mode the MsQuic receiving callback is disabled.

*** Callback handle `QUIC_STREAM_EVENT_RECEIVE` in Passive mode

Quicer utilize the "Asynchronous receive" and "Partial Data Acceptance" functionalities provided by MsQuic.

In passive mode, stream *recv callback* returns `QUIC_STATUS_PENDING` to enable "Asynchronous receive", this pauses the further
receiving callbacks until `quicer:recv` is called. The `is_recv_pending` of stream ctx is set to mark the recv is pending and wait for
a `StreamReceiveComplete` to complete the receive.

If `quicer:recv` is called before recv callback (is_recv_pending is not set) which means the application
is blocked from receiving the data. Quicer will send a 'recv continue' msg as below to the stream owner to unblock the owner.
#+begin_src erlang
{quic, continue, stream_handle(), undefined}
#+end_src

*** quicer:recv/2 call in Passive Mode

The NIF (`quicer_nif:recv/2`) first check if `is_recv_pending` is set.

If TRUE, NIF will copy the data it needs and call `StreamReceiveComplete` to mark handled data and return the binary to the caller.
The side effect of calling `StreamReceiveComplete` is it completes the *async recv* handling and reenables the recv callback if all
data in the recv buffer is consumed. If it is partially consumed, the stream receving will be left disabled as it is in passive mode.
NOTE, duplicate `StreamReceiveComplete` calls could cause undefined behaviors. see [MsQuic/docs/Streams.md]

If FALSE, NIF will mark `is_wait_for_data` in stream ctx and return `{error, not_ready}` to the caller and the caller should
wait for recv `continue` message mentioned above.

*** quicer:recv/2 call in Active Mode

Should return error.

*** Mode switching

**** From passive to active

Call `StreamReceiveComplete` if `is_recv_pending` is set to complete the async recv.

and then call `StreamReceiveSetEnabled` to enable the recv.

**** From active to passive

After set to {active, false}, owner should remember to  handle the binary data in message box before
active false takes effect.
